{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python setup.py install &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from cache...\n",
      "Loaded 2196 ECG samples in total.\n"
     ]
    }
   ],
   "source": [
    "import argparse, pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from src.trainers import ContrastiveLearning\n",
    "from src.utils import yaml_config_hook\n",
    "from src.loaders import get_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# create args parser and link to Lightning trainer:\n",
    "parser = argparse.ArgumentParser(description=\"demo\")\n",
    "parser = Trainer.add_argparse_args(parser)\n",
    "\n",
    "# extract args from config file and add to parser:\n",
    "config = yaml_config_hook(\"config/config_ptbxl.yaml\")\n",
    "for key, value in config.items():\n",
    "    parser.add_argument(f\"--{key}\", default=value, type=type(value))\n",
    "args = parser.parse_args()\n",
    "\n",
    "# set random seed if selected:\n",
    "if args.seed:\n",
    "    pl.seed_everything(args.seed, workers=True)\n",
    "\n",
    "test_dataset = get_dataset(\n",
    "    dataset=args.dataset,\n",
    "    dataset_dir=args.dataset_dir,\n",
    "    sr=args.sr,\n",
    "    split=\"test\",\n",
    "    gtruth=args.gtruth,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=args.workers,\n",
    "    drop_last=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import ResNet1D\n",
    "\n",
    "encoder = ResNet1D(\n",
    "    in_channels=args.in_channels,\n",
    "    base_filters=args.base_filters,\n",
    "    kernel_size=args.kernel_size,\n",
    "    stride=args.stride,\n",
    "    groups=args.groups,\n",
    "    n_block=args.n_block,\n",
    "    n_classes=args.n_classes,\n",
    ")\n",
    "\n",
    "ckpt_path = \"ckpt/BIG_epoch=99-step=97300.ckpt\"\n",
    "model = ContrastiveLearning.load_from_checkpoint(ckpt_path, encoder=encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data torch.Size([256, 1000])\n",
      "data tensor([[ 0.4734,  0.8819,  1.1655,  ..., -1.0835, -0.8118, -0.0294],\n",
      "        [ 0.0104,  0.2959, -1.7159,  ..., -0.4874, -0.0981,  0.1750],\n",
      "        [-0.1190,  0.0362,  0.2389,  ..., -1.3782, -0.8564,  0.0424],\n",
      "        ...,\n",
      "        [-0.1013, -0.1572, -0.2031,  ..., -0.2356, -0.1528, -0.0526],\n",
      "        [ 0.1494,  0.1372,  0.1251,  ..., -0.1884, -0.2308,  0.0739],\n",
      "        [ 0.0145, -1.0351, -1.1175,  ...,  0.9049,  0.5642,  0.0998]],\n",
      "       dtype=torch.float64)\n",
      "label torch.Size([256, 5])\n",
      "label tensor([[1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 1, 0],\n",
      "        [0, 1, 0, 1, 0]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:48<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "iteration over a 0-d tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m evaluate\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m metrics, _ \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/hume/ACS/playground/tiles_ecg_model/src/utils/eval.py:122\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, dataset, dataset_name, aggregate, modalities)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m, label\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m, label)\n\u001b[0;32m--> 122\u001b[0m preds, y \u001b[38;5;241m=\u001b[39m model(data, label)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mptb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m dataset_name\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAVEC\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m dataset_name\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEPIC\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m dataset_name\n\u001b[1;32m    127\u001b[0m ):\n\u001b[1;32m    128\u001b[0m     preds \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_tensor.py:1109\u001b[0m, in \u001b[0;36mTensor.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;66;03m# NB: we use 'imap' and not 'map' here, so that in Python 2 we get a\u001b[39;00m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;66;03m# generator and don't eagerly perform all the indexes.  This could\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1106\u001b[0m     \u001b[38;5;66;03m# NB: We have intentionally skipped __torch_function__ dispatch here.\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;66;03m# See gh-54457\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1109\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration over a 0-d tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state():\n\u001b[1;32m   1111\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1112\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterating over a tensor might cause the trace to be incorrect. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1113\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing a tensor of different shape won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt change the number of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1117\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   1118\u001b[0m         )\n",
      "\u001b[0;31mTypeError\u001b[0m: iteration over a 0-d tensor"
     ]
    }
   ],
   "source": [
    "from src.utils import evaluate\n",
    "import torch\n",
    "\n",
    "metrics, _ = evaluate(\n",
    "    model.to(torch.device(\"cpu\")),\n",
    "    dataset=test_loader,\n",
    "    dataset_name=args.dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andresalvarezolmo/.pyenv/versions/3.10.16/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Users/andresalvarezolmo/.pyenv/versions/3.10.16/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:262: UserWarning: Attribute 'encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['encoder'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "from src.models import S4Model\n",
    "\n",
    "encoder = S4Model(\n",
    "    d_input=args.d_input,\n",
    "    d_output=args.d_output,\n",
    "    d_model=args.d_model,\n",
    "    n_layers=args.n_layers,\n",
    "    dropout=args.dropout,\n",
    "    prenorm=True,\n",
    ")\n",
    "\n",
    "ckpt_path = \"ckpt/s4_contr.ckpt\"\n",
    "model = ContrastiveLearning.load_from_checkpoint(ckpt_path, encoder=encoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
